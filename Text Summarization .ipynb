{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2018/11/introduction-text-summarization-textrank-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tennis_articles_v4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maria Sharapova has basically no friends as te...</td>\n",
       "      <td>https://www.tennisworldusa.org/tennis/news/Mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>BASEL, Switzerland (AP), Roger Federer advance...</td>\n",
       "      <td>http://www.tennis.com/pro-game/2018/10/copil-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Roger Federer has revealed that organisers of ...</td>\n",
       "      <td>https://scroll.in/field/899938/tennis-roger-fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kei Nishikori will try to end his long losing ...</td>\n",
       "      <td>http://www.tennis.com/pro-game/2018/10/nishiko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Federer, 37, first broke through on tour over ...</td>\n",
       "      <td>https://www.express.co.uk/sport/tennis/1036101...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                       article_text  \\\n",
       "0           1  Maria Sharapova has basically no friends as te...   \n",
       "1           2  BASEL, Switzerland (AP), Roger Federer advance...   \n",
       "2           3  Roger Federer has revealed that organisers of ...   \n",
       "3           4  Kei Nishikori will try to end his long losing ...   \n",
       "4           5  Federer, 37, first broke through on tour over ...   \n",
       "\n",
       "                                              source  \n",
       "0  https://www.tennisworldusa.org/tennis/news/Mar...  \n",
       "1  http://www.tennis.com/pro-game/2018/10/copil-s...  \n",
       "2  https://scroll.in/field/899938/tennis-roger-fe...  \n",
       "3  http://www.tennis.com/pro-game/2018/10/nishiko...  \n",
       "4  https://www.express.co.uk/sport/tennis/1036101...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Maria Sharapova has basically no friends as tennis players on the WTA Tour. The Russian player has no problems in openly speaking about it and in a recent interview she said: 'I don't really hide any feelings too much. I think everyone knows this is my job here. When I'm on the courts or when I'm on the court playing, I'm a competitor and I want to beat every single person whether they're in the locker room or across the net.So I'm not the one to strike up a conversation about the weather and know that in the next few minutes I have to go and try to win a tennis match. I'm a pretty competitive girl. I say my hellos, but I'm not sending any players flowers as well. Uhm, I'm not really friendly or close to many players. I have not a lot of friends away from the courts.' When she said she is not really close to a lot of players, is that something strategic that she is doing? Is it different on the men's tour than the women's tour? 'No, not at all. I think just because you're in the same sport doesn't mean that you have to be friends with everyone just because you're categorized, you're a tennis player, so you're going to get along with tennis players. I think every person has different interests. I have friends that have completely different jobs and interests, and I've met them in very different parts of my life. I think everyone just thinks because we're tennis players we should be the greatest of friends. But ultimately tennis is just a very small part of what we do. There are so many other things that we're interested in, that we do.'\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['article_text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Text into Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sentences = []\n",
    "for s in df['article_text']:\n",
    "  sentences.append(sent_tokenize(s))\n",
    "\n",
    "sentences = [y for x in sentences for y in x] # flatten list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Maria Sharapova has basically no friends as tennis players on the WTA Tour.',\n",
       " \"The Russian player has no problems in openly speaking about it and in a recent interview she said: 'I don't really hide any feelings too much.\",\n",
       " 'I think everyone knows this is my job here.',\n",
       " \"When I'm on the courts or when I'm on the court playing, I'm a competitor and I want to beat every single person whether they're in the locker room or across the net.So I'm not the one to strike up a conversation about the weather and know that in the next few minutes I have to go and try to win a tennis match.\",\n",
       " \"I'm a pretty competitive girl.\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  GloVe Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract word vectors\n",
    "word_embeddings = {}\n",
    "f = open('glove.6B.100d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.038194, -0.24487 ,  0.72812 , -0.39961 ,  0.083172,  0.043953,\n",
       "       -0.39141 ,  0.3344  , -0.57545 ,  0.087459,  0.28787 , -0.06731 ,\n",
       "        0.30906 , -0.26384 , -0.13231 , -0.20757 ,  0.33395 , -0.33848 ,\n",
       "       -0.31743 , -0.48336 ,  0.1464  , -0.37304 ,  0.34577 ,  0.052041,\n",
       "        0.44946 , -0.46971 ,  0.02628 , -0.54155 , -0.15518 , -0.14107 ,\n",
       "       -0.039722,  0.28277 ,  0.14393 ,  0.23464 , -0.31021 ,  0.086173,\n",
       "        0.20397 ,  0.52624 ,  0.17164 , -0.082378, -0.71787 , -0.41531 ,\n",
       "        0.20335 , -0.12763 ,  0.41367 ,  0.55187 ,  0.57908 , -0.33477 ,\n",
       "       -0.36559 , -0.54857 , -0.062892,  0.26584 ,  0.30205 ,  0.99775 ,\n",
       "       -0.80481 , -3.0243  ,  0.01254 , -0.36942 ,  2.2167  ,  0.72201 ,\n",
       "       -0.24978 ,  0.92136 ,  0.034514,  0.46745 ,  1.1079  , -0.19358 ,\n",
       "       -0.074575,  0.23353 , -0.052062, -0.22044 ,  0.057162, -0.15806 ,\n",
       "       -0.30798 , -0.41625 ,  0.37972 ,  0.15006 , -0.53212 , -0.2055  ,\n",
       "       -1.2526  ,  0.071624,  0.70565 ,  0.49744 , -0.42063 ,  0.26148 ,\n",
       "       -1.538   , -0.30223 , -0.073438, -0.28312 ,  0.37104 , -0.25217 ,\n",
       "        0.016215, -0.017099, -0.38984 ,  0.87424 , -0.72569 , -0.51058 ,\n",
       "       -0.52028 , -0.1459  ,  0.8278  ,  0.27062 ], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuations, numbers and special characters\n",
    "clean_sentences = pd.Series(sentences).str.replace(\"[^a-zA-Z]\", \" \")\n",
    "\n",
    "# make alphabets lowercase\n",
    "clean_sentences = [s.lower() for s in clean_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove stopwords\n",
    "def remove_stopwords(sen):\n",
    "    sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
    "    return sen_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords from the sentences\n",
    "clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['maria sharapova basically friends tennis players wta tour',\n",
       " 'russian player problems openly speaking recent interview said really hide feelings much',\n",
       " 'think everyone knows job',\n",
       " 'courts court playing competitor want beat every single person whether locker room across net one strike conversation weather know next minutes go try win tennis match',\n",
       " 'pretty competitive girl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Representation of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vectors = []\n",
    "for i in clean_sentences:\n",
    "  if len(i) != 0:\n",
    "    v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
    "  else:\n",
    "    v = np.zeros((100,))\n",
    "  sentence_vectors.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.14825583e-02,  1.10544682e-01,  6.94999397e-01,  1.89168096e-01,\n",
       "       -9.58077684e-02,  3.20288986e-01,  2.70662010e-01,  5.42440832e-01,\n",
       "       -3.05938005e-01, -1.56364068e-01,  3.70127618e-01,  8.09492469e-02,\n",
       "        8.41393881e-03,  2.47571543e-01, -3.69342804e-01, -7.61044994e-02,\n",
       "        8.08582604e-02,  2.30643645e-01, -2.70402402e-01,  5.13828397e-01,\n",
       "       -6.12548441e-02,  3.87900352e-01,  1.03121363e-01,  7.72494674e-01,\n",
       "        2.59960234e-01, -7.96069205e-02,  1.42143592e-01, -9.62644577e-01,\n",
       "        7.54904330e-01,  6.03260659e-02, -4.58570123e-01,  2.36780301e-01,\n",
       "        2.29152635e-01, -1.56453326e-01,  3.97632688e-01, -2.32720934e-02,\n",
       "       -5.05520999e-01,  4.13252831e-01, -2.85759270e-01, -1.35231465e-01,\n",
       "       -1.37098104e-01, -1.48972601e-01,  3.37537557e-01, -3.49540442e-01,\n",
       "        1.53484434e-01, -2.33341649e-01, -1.98460802e-01, -1.27821520e-01,\n",
       "        5.08063912e-01, -3.68636876e-01, -2.28472307e-01, -3.15306723e-01,\n",
       "        1.36149466e-01,  2.22507194e-01,  1.19500056e-01, -1.71007359e+00,\n",
       "       -1.04403630e-01,  3.45346779e-01,  5.54419458e-01,  7.91236103e-01,\n",
       "       -2.63593912e-01,  5.01183808e-01, -1.54918820e-01,  2.39762396e-01,\n",
       "       -4.94388118e-02, -1.39404953e-01, -6.96142530e-03,  4.52243447e-01,\n",
       "        1.44498184e-01, -1.88242078e-01,  1.62694290e-01,  2.51032356e-02,\n",
       "       -1.29925504e-01, -2.16523811e-01, -1.39851749e-01,  1.79708660e-01,\n",
       "        4.75623786e-01,  6.25944212e-02, -1.11897260e-01, -1.08534172e-01,\n",
       "        6.22914493e-01, -2.60313332e-01, -1.83883741e-01,  1.65396854e-02,\n",
       "       -1.04412448e+00, -3.77867967e-01, -6.96135521e-01,  2.54875660e-01,\n",
       "       -2.14379832e-01, -6.60440326e-02, -3.04694414e-01, -2.49966215e-02,\n",
       "        3.12481433e-01,  1.38415188e-01,  1.15484960e-01,  9.44008352e-04,\n",
       "       -3.47184688e-01, -5.04137203e-02,  3.52187961e-01,  5.41942239e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_vectors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Matrix Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to find similarities between the sentences, and we will use the cosine similarity approach for this challenge. Let’s create an empty similarity matrix for this task and populate it with cosine similarities of the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity matrix\n",
    "sim_mat = np.zeros([len(sentences), len(sentences)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Cosine Similarity to compute the similarity between a pair of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "  for j in range(len(sentences)):\n",
    "    if i != j:\n",
    "      sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100), sentence_vectors[j].reshape(1,100))[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.64378339, 0.59156996, 0.7475453 , 0.63747269,\n",
       "       0.61883837, 0.69372612, 0.68542236, 0.64739478, 0.79788285,\n",
       "       0.        , 0.83178782, 0.55843717, 0.58564365, 0.79771841,\n",
       "       0.7565254 , 0.575041  , 0.78072816, 0.76926839, 0.76079887,\n",
       "       0.69774014, 0.57463962, 0.76672947, 0.76485747, 0.70574647,\n",
       "       0.65560281, 0.68210036, 0.75054377, 0.75795829, 0.76086783,\n",
       "       0.77791655, 0.72807384, 0.51281953, 0.62611955, 0.75033784,\n",
       "       0.72495872, 0.73631626, 0.80387628, 0.76793849, 0.79761171,\n",
       "       0.60056752, 0.5711596 , 0.4839384 , 0.60865247, 0.76039338,\n",
       "       0.65742689, 0.79201418, 0.69379342, 0.77095509, 0.72267765,\n",
       "       0.63604903, 0.68510795, 0.72176009, 0.76703787, 0.7127533 ,\n",
       "       0.72431403, 0.69582933, 0.67656857, 0.71721417, 0.75621694,\n",
       "       0.79263107, 0.80084306, 0.75121981, 0.71313131, 0.69707161,\n",
       "       0.51949501, 0.79594338, 0.65058309, 0.71506596, 0.63255179,\n",
       "       0.77398628, 0.76161532, 0.55275261, 0.64103466, 0.56029499,\n",
       "       0.54062003, 0.6279726 , 0.8576681 , 0.79139078, 0.82140797,\n",
       "       0.74730194, 0.7665751 , 0.76181114, 0.84109718, 0.72565573,\n",
       "       0.75210363, 0.78193176, 0.78741208, 0.70137333, 0.65684301,\n",
       "       0.73265982, 0.72487068, 0.6032747 , 0.81301349, 0.7691083 ,\n",
       "       0.67314768, 0.81562442, 0.72426933, 0.71994776, 0.76669145,\n",
       "       0.71265775, 0.77899873, 0.79071653, 0.78243649, 0.65212744,\n",
       "       0.65465164, 0.73735297, 0.66690505, 0.81240171, 0.67056549,\n",
       "       0.79748607, 0.67637658, 0.41215223, 0.64423269, 0.73797786,\n",
       "       0.64350599, 0.72776717, 0.5850122 , 0.68277591])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_mat[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying PageRank Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "nx_graph = nx.from_numpy_array(sim_mat)\n",
    "scores = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When I'm on the courts or when I'm on the court playing, I'm a competitor and I want to beat every single person whether they're in the locker room or across the net.So I'm not the one to strike up a conversation about the weather and know that in the next few minutes I have to go and try to win a tennis match.\n",
      "Major players feel that a big event in late November combined with one in January before the Australian Open will mean too much tennis and too little rest.\n",
      "Speaking at the Swiss Indoors tournament where he will play in Sundays final against Romanian qualifier Marius Copil, the world number three said that given the impossibly short time frame to make a decision, he opted out of any commitment.\n",
      "\"I felt like the best weeks that I had to get to know players when I was playing were the Fed Cup weeks or the Olympic weeks, not necessarily during the tournaments.\n",
      "Currently in ninth place, Nishikori with a win could move to within 125 points of the cut for the eight-man event in London next month.\n",
      "He used his first break point to close out the first set before going up 3-0 in the second and wrapping up the win on his first match point.\n",
      "The Spaniard broke Anderson twice in the second but didn't get another chance on the South African's serve in the final set.\n",
      "\"We also had the impression that at this stage it might be better to play matches than to train.\n",
      "The competition is set to feature 18 countries in the November 18-24 finals in Madrid next year, and will replace the classic home-and-away ties played four times per year for decades.\n",
      "Federer said earlier this month in Shanghai in that his chances of playing the Davis Cup were all but non-existent.\n"
     ]
    }
   ],
   "source": [
    "# Extract top 10 sentences as the summary\n",
    "for i in range(10):\n",
    "  print(ranked_sentences[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
